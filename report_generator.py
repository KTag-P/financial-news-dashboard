
import simple_summarizer
from collections import Counter
import re
from datetime import datetime


def extract_keywords(text, top_n=5, target_company=None):
    """
    Extracts top N keywords, boosting those that appear near the target company.
    """
    stopwords = set(["ë‰´ìŠ¤", "ê¸°ì", "ë°í˜”ë‹¤", "ë”°ë¥´ë©´", "ìˆë‹¤", "ê²ƒìœ¼ë¡œ", "ëŒ€í•œ", "ìœ„í•´", "í†µí•´", "ì§€ë‚œ", "ì´ë²ˆ", "ê²½ìš°", "ê´€ë ¨", "ë“±", "ë°", "ì´", "ê·¸", "ì €", "ìˆ˜", "ê²ƒ", "ë“¤", "ì œ", "ê°œ", "ì „", "í›„", "ë„¤", "ì•„", "íœ´", "ì•„ì´êµ¬", "ì•„ì´ì¿ ", "ì•„ì´ê³ ", "ì–´", "ë‚˜", "ìš°ë¦¬", "ì €í¬", "ë”°ë¼", "ì˜í•´", "ì„", "ë¥¼", "ì—", "ì˜", "ê°€", "ìœ¼ë¡œ", "ë¡œ", "ì—ê²Œ", "ë¿ì´ë‹¤", "ì˜ê±°í•˜ì—¬", "ê·¼ê±°í•˜ì—¬", "ì…ê°í•˜ì—¬", "ê¸°ì¤€ìœ¼ë¡œ", "ì˜ˆí•˜ë©´", "ì˜ˆë¥¼", "ë“¤ë©´", "ë“¤ìë©´", "ì €ê¸°", "ì €ìª½", "ì €ê²ƒ", "ê·¸ë•Œ", "ê·¸ëŸ¼", "ê·¸ëŸ¬ë©´", "ìš”ì»¨ëŒ€", "ë‹¤ì‹œ", "ë§í•˜ìë©´", "ë§í•˜ë©´", "ì¦‰", "êµ¬ì²´ì ìœ¼ë¡œ", "ë§í•´", "ì‹œì‘í•˜ì—¬", "ê´€í•˜ì—¬", "ë¹„ê¸¸ìˆ˜", "ì—†ë‹¤", "í•˜ê¸°", "ë•Œë¬¸ì—", "ê·¸", "ì—¬ëŸ¬ë¶„", "ì±„ìš©", "ê³µê³ ", "ëª¨ì§‘"])
    
    # Competitor names to exclude from keywords
    competitors = ["ì‹ í•œ", "KB", "êµ­ë¯¼", "ìš°ë¦¬", "í•˜ë‚˜", "ë¡¯ë°", "í˜„ëŒ€", "ì‚¼ì„±", "BC"]
    
    words = re.findall(r'\w+', text)
    filtered_words = []
    
    for w in words:
        if len(w) > 1 and w not in stopwords:
            # Exclude competitor names if valid
            if not any(c in w for c in competitors):
                filtered_words.append(w)
    
    # Weight certain financial keywords
    weighted_words = []
    for w in filtered_words:
        weighted_words.append(w)
        if w in ["ê¸ˆë¦¬", "PF", "ë¶€ë™ì‚°", "ì‹¤ì ", "ìˆœì´ìµ", "ë°°ë‹¹", "ì£¼ê°€", "ë°œí–‰", "ì±„ê¶Œ", "CEO", "ì¸ì‚¬", "ë””ì§€í„¸", "í”Œë«í¼", "ì‹ ê¸°ìˆ ", "í€ë“œ", "íˆ¬ì"]:
            weighted_words.append(w) # Add again to boost
            
    return [item[0] for item in Counter(weighted_words).most_common(top_n)]

def generate_synthesis_report(news_items, title="ì›”ê°„ í•µì‹¬ ë¦¬í¬íŠ¸", company_name=""):
    """
    Generates a synthesized report focused strictly on the target company.
    """
    now = datetime.now().strftime("%Y-%m-%d")
    
    target_kws = []
    if "IBK" in title or "IBK" in company_name: target_kws = ["IBK", "ê¸°ì—…ì€í–‰"]
    elif "ì‚°ì€" in title or "KDB" in company_name: target_kws = ["KDB", "ì‚°ì€", "ì‚°ì—…ì€í–‰"]
    
    competitors = ["ì‹ í•œ" , "KB", "êµ­ë¯¼", "ìš°ë¦¬", "í•˜ë‚˜", "ë¡¯ë°", "í˜„ëŒ€", "ì‚¼ì„±"]

    # 1. Combine & Filter Text
    relevant_sentences = []
    all_text_for_keywords = ""
    
    for item in news_items:
        content = item.get('full_content', '') or item.get('summary', '')
        # Split into sentences
        sentences = re.split(r'(?<=[.?!])\s+', content)
        for s in sentences:
            s_clean = simple_summarizer.clean_text(s)
            if len(s_clean) < 20: continue
            
    # ... (inside loop)
            # Context Filtering
            # Condition 0: Strict Junk Filter (Captions, Attendee Lists)
            if s_clean.startswith("(") or s_clean.startswith("[") or "ì™¼ìª½ë¶€í„°" in s_clean or "ì˜¤ë¥¸ìª½ë¶€í„°" in s_clean or "ê¸°ë…ì´¬ì˜" in s_clean:
                continue

            # Condition 1: Must not be primarily about a competitor (unless target is also mentioned)
            is_competitor_news = any(c in s_clean for c in competitors)
            is_target_news = any(t in s_clean for t in target_kws) if target_kws else True
            
            if is_competitor_news and not is_target_news:
                continue # Skip pure competitor news
                
            relevant_sentences.append(s_clean)
            all_text_for_keywords += s_clean + " "

    if not relevant_sentences:
        return "ë¶„ì„í•  ê´€ë ¨ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    full_relevant_text = " ".join(relevant_sentences)

    # 2. Extract Top Themes (from filtered text)
    keywords = extract_keywords(full_relevant_text, top_n=5, target_company=target_kws[0] if target_kws else None)
    
    # 3. Generate Executive Summary (Focus on Target + Business Score)
    # We prioritize sentences that have the target keyword AND high business score
    scored_candidates = []
    
    # Define Business Keywords
    business_kws = ["ìˆœì´ìµ", "ì‹¤ì ", "íˆ¬ì", "í€ë“œ", "ì„±ì¥", "ê¸ˆìœµ", "ì§€ì›", "MOU", "ì „ëµ", "ë””ì§€í„¸", "ì˜ì—…", "ìì‚°", "ë°œí–‰", "ì±„ê¶Œ", "í™•ëŒ€", "ê°•í™”"]
    junk_kws = ["ì°¸ì„", "ê°œìµœ", "ì‚¬ì§„", "ì˜¤ì „", "ì˜¤í›„", "ì„œìš¸", "í˜¸í…”", "ì·¨ì„", "ì¸ì‚¬", "ë°©ë¬¸", "ê¸°ë…", "ë³´ìˆ˜", "ì—°ë´‰", "ì‚¬ì™¸ì´ì‚¬", "ì§€ê¸‰", "ê¸°ë¶€", "ì„±ê¸ˆ", "ë´‰ì‚¬", "ì „ë‹¬", "ë‚˜ëˆ”", "í›„ì›"]

    for s in relevant_sentences:
        score = 0
        # Base Score: Target Company Mention
        if target_kws and any(t in s for t in target_kws):
             score += 10
        
        # Business Score
        for bk in business_kws:
            if bk in s: score += 5
            
        # Junk Score (Penalty)
        for jk in junk_kws:
            if jk in s: score -= 5
            
        # Length Score (Too short is bad, too long is okay if informative)
        if len(s) < 30: score -= 10
        
        # Competitor Penalty for Executive Summary (Strict)
        if any(c in s for c in competitors): score -= 5

        scored_candidates.append((score, s))
    
    # Sort by score desc
    scored_candidates.sort(key=lambda x: x[0], reverse=True)
    
    # Pick Top 5 Unique High-Scoring Sentences
    top_exec_sentences = []
    seen_exec = set()
    for score, s in scored_candidates:
        if len(top_exec_sentences) >= 5: break
        if score > 5 and s not in seen_exec: # Minimum threshold
             top_exec_sentences.append(s)
             seen_exec.add(s)
    
    if not top_exec_sentences: # Fallback
        top_exec_sentences = [s for _, s in scored_candidates[:3]]

    exec_summary_bullets = ""
    for s in top_exec_sentences:
         exec_summary_bullets += f"- {s.strip()}.\n"
    
    # 4. Generate Theme-based Sections
    theme_sections = ""
    used_sentences = set()
    
    for kw in keywords:
        # Avoid the target company name itself as a "theme" (too broad)
        if target_kws and any(t in kw for t in target_kws): continue
        if len(kw) < 2: continue
        
        # Find sentences containing the keyword AND strictly relevant
        theme_candidates = []
        for s in relevant_sentences:
            if kw in s:
                # Double check competitor filtering
                if any(c in s for c in competitors) and not (target_kws and any(t in s for t in target_kws)):
                    continue
                
                if s not in used_sentences and len(s) < 300:
                    theme_candidates.append(s)
                    used_sentences.add(s)
        
        if theme_candidates:
            # Pick top 2-3
            top_sentences = sorted(list(set(theme_candidates)), key=len, reverse=True)[:3]
            theme_sections += f"#### ğŸ”‘ {kw}\n"
            for s in top_sentences:
                theme_sections += f"- {s.strip()}\n"
            theme_sections += "\n"

    # 5. Build Final Markdown
    report = f"""
## ğŸ“‘ {company_name} ê²½ì˜ ë¶„ì„ ë¦¬í¬íŠ¸ (Briefing)
**ìƒì„±ì¼**: {now} | **ë¶„ì„ ëŒ€ìƒ**: {len(news_items)}ê±´ì˜ ê¸°ì‚¬ ì¤‘ ê´€ë ¨ ë‚´ìš© ì¶”ì¶œ

### ğŸŒŸ ì¢…í•© ìš”ì•½ (Executive Summary)
> **í•µì‹¬ íŠ¸ë Œë“œ**: {company_name} ê´€ë ¨ ì£¼ìš” ì´ìŠˆì™€ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

{exec_summary_bullets}

---

### ğŸ” ì£¼ìš” í…Œë§ˆë³„ ì‹¬ì¸µ ë¶„ì„ (Deep Dive)
**{company_name}**ì˜ ê´€ì ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.

{theme_sections}

---

### ğŸ“š ì¶œì²˜ (Sources)
"""
    for item in news_items[:10]: # List top 10 titles
        date = item.get('published', '')[:10]
        report += f"1. **[{date}]** {item.get('title')}\n"
        
    return report
